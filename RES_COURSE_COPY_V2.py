"""The following are the steps for this course copy script:
	1. download a provisioning report from the RES Subaccount to get the current list of sections generated by CBS.
	2. query UTL_D_LMS.resdevs table to get a complete list of resdevs created and their ids
	3. run content migration for any course that is marked as ready in Academics' master list
	4. The script:
					a. verifies that content migration has never been run for each course.
					b. pulls oracle credentials for oracle_connect() and Canvas token from environmental variables
					c. initiates migration, stores status URL and moves on to the next. It then later verifies completion
"""

#LIST OF MODULES USED IN THIS SCRIPT
from os import environ, system, remove, path
import requests
import csv
import time
import urllib.request
from datetime import datetime
import cx_Oracle 


#DEFINITIONS
INSTANCE = environ['L2CAN_URL'] +'%s'
ACCOUNT_URL = INSTANCE  %'accounts/'
COURSE_URL = INSTANCE %'courses/'
SIS_USER_URL = INSTANCE % 'users/sis_user_id:'
TOKEN = environ['L2CAN_TOKEN']
HEADER = {'Authorization': 'Bearer %s' % TOKEN}
desktop = path.join(path.join(environ['USERPROFILE']), 'Desktop\\')
masterlist = desktop + 'source_file.csv'

system('cls')						#i run my scripts in CMD so just a habit clearing screen with each test/run
account_id = 158
live_dict = {}
resdev_dict = {}
error_log = []
migration_status = []
xlist = []
copied = []

SQL = """ 	SELECT c.id, c.name

			FROM canvas_etl.courses c

			WHERE INSTANCE = 'L2CAN'
			AND   c.course_code LIKE '%RESDEV%202040R'  
			AND   c.workflow_state <> 'deleted' """

#PROVISIONING REPORT FUNCTIONS
def get_provisioning_csv(account_id):
	"""generates a provisioning report and returns url and file name"""
	report_id =  0
	progress = 0

	payload={'parameters[courses]': True}
	request = requests.post(ACCOUNT_URL + str(account_id) + '/reports/provisioning_csv', params=payload, headers=HEADER)
	response = request.json()
	#print(response)
	print(response['report'], response['id'], response['parameters'], response['created_at'], '\n')

	report_id = response['id']

	while progress != 100:
		request = requests.get(ACCOUNT_URL + str(account_id) + '/reports/provisioning_csv/' + str(report_id), params=payload, headers=HEADER)
		response = request.json()
		progress = response['progress']
		print('	provisioning report progress is at:', progress)

		if progress != 100:
			time.sleep(10)
		elif progress == 100:
			file_name = response['attachment']['display_name']
			file_url = response['attachment']['url']
			break

	return file_url, file_name

def delete_csv(file, name):
	"""deletes file"""
	remove(file)
	print('\n', name, 'has been deleted')

def get_file(url, name):
	"""downloads file"""
	urllib.request.urlretrieve(url, desktop + name)
	return desktop + name

#CONTENT MIGRATION FUNCTIONS
def content_migrator(old_id, new_id):
	"""this function uses the content migration api endpoint to copy course content to another course"""
	print('migrating content from', old_id)

	payload = {"migration_type" : "course_copy_importer",
	   "settings[source_course_id]" : old_id}


	request = requests.post(COURSE_URL + str(new_id) + '/content_migrations', params=payload, headers=HEADER)
	response = request.json()
	try:
		print(response['workflow_state'], '\n')
		migration_status.append(response['progress_url'])
	except:
		content_migrator(old_id, new_id)

def verify_migration():
	#this function veries that all migrations completed and throws a warning if not completed or running.
	for i in migration_status:
		request = requests.get(str(i), headers=HEADER)
		mig = request.json()

		try:

			if mig['workflow_state'] not in ['running', 'completed', 'queued']:
				warning = f"WARNING: {mig['settings']['source_course_id']} {mig['settings']['source_course_name']} has a workflow state of {mig['workflow_state']}"
				error_log.append(warning)
				print(warning)
			else:
				print(mig['workflow_state'], mig['completion'], i)
		except KeyError:
			print('MIGRATION ERROR:', mig)
			error_log.append(f'ERROR: {mig} does not exist in Canvas')

#ORACLE FUNCTIONS
def oracle_connect():
	#Database credentials
	dbuser = environ.get('DBUSERNAME') #proxy access to schema
	dbpass = environ.get('DBPW')
	dbase = 'WHPRD_USR'

	#creates oracle connection
	conn = cx_Oracle.connect(dbuser, dbpass, dbase, encoding="UTF-8", nencoding="UTF-8")

	return conn

def oracle_run(SQL, conn):
 	#runs SQL queries
	cursor = conn.cursor()
	cursor.execute(SQL)
	return cursor

#DICTIONARY FUNCTIONS
def live_sections_dictionary(file):
	#takes provisioning report and generates a dictionary of sections and ids
	with open(file) as csv_file:
		response = csv.reader(csv_file, delimiter=',')
		next(response)
		for course in response:
			live_dict.update({course[1]:course[0]})
		print('generating live sections dictionary')

def xlist_dictionary():
	#runs sql to get list of xlist and ids generates a dictionary from it
	c_sql = """SELECT x.ssrxlst_term_code || x.ssrxlst_crn bannersectionid FROM ssrxlst x WHERE x.ssrxlst_term_code = '202040' """

	print('connecting to ORACLE database')
	conn = oracle_connect()
	results = oracle_run(c_sql, conn)

	print('generating xlist courses\n')
	for bannersectionid in results:
		xlist.append(bannersectionid[0])
	
def resdev_dictionary(SQL):
	#runs sql to get list of resdevs and ids generates a dictionary from it
	print('connecting to ORACLE database')
	conn = oracle_connect()
	results = oracle_run(SQL, conn)

	print('generating resdev list from UTL_D_LMS\n')
	for course_id, name in results:
		resdev_dict.update({name:course_id})

def copied_list():
	"""this function runs the sql below to get all courses that have had content copied in them"""
	NSQL = """SELECT DISTINCT c1.sis_source_id
																   
				FROM canvas_etl.content_migrations cm

				JOIN canvas_etl.courses c1
				ON   c1.id = cm.context_id
				AND  c1.instance = cm.instance
				AND  c1.workflow_state != 'deleted'
				AND  c1.sis_source_id IS NOT NULL

				JOIN canvas_etl.courses c2
				ON   c2.id = cm.source_course_id
				AND  c2.instance = cm.instance
				AND  c2.workflow_state != 'deleted'
				AND  c2.course_code LIKE '%RESDEV%'

				WHERE cm.instance = 'L2CAN' """

	print('connecting to ORACLE database')
	conn = oracle_connect()
	results = oracle_run(NSQL, conn)

	print('generating copied list\n')
	for course in results:
		copied.append(course[0])

#PROCESS FUNCTIONS
def verify_course_copy(sisid):
	"""returns true if id is in the copied list"""
	return sisid in copied

def verify_api_copy(course_id):
	"""makes an API call to see if content has been copied into course"""
	request = requests.get(COURSE_URL + str(course_id) + '/content_migrations', headers=HEADER)
	response = request.json()

	return bool(response)

def verify_xlist(bannersectionid):
	"""returns true if id is in xlisted list"""
	return bannersectionid in xlist

def error_handling(sysdate):
	"""prints error log to file"""
	print('.....error handling csv')
	error_file = desktop + f'ERROR_LOG_course_copy{sysdate}.csv'
	with open(error_file, 'w', newline='') as csvfile:
		spamwriter = csv.writer(csvfile)
		for error in error_log:
			spamwriter.writerow([error])	

def read_csv(file):
	#reads masterlist.csv and if course qualifies to be copied intiates content migration.
	#this function also generates error log list if section doesn't exist in Canvas, if resdev id not provided or unknown error occurs

	with open(file) as csv_file:
		response = csv.reader(csv_file, delimiter=',')
		next(response)
		for course in response:
			try:
				if verify_xlist(course[1]) == False and not(verify_course_copy(course[1]) == True or verify_api_copy(live_dict[course[1]]) == True):
					#print('	XLST:', verify_xlist(course[1]), 'DATA:', verify_course_copy(course[1]), 'API:', verify_api_copy(live_dict[course[1]]), '\n\n')

					#if course is marked yes for copy, resdev id in CSV and live section id in live_dict
					if course[-1].lower() == 'yes' and course[-3] and live_dict[course[1]]:

							from_id = course[-3]
							to_id = live_dict[course[1]]
							print(f'copying to: {to_id} - {course[1]} from: {from_id} - {course[-2]}')
							content_migrator(from_id, to_id ) #initiates course copy

					#if course is marked yes for copy, section id in live_dict but resdev ID is NOT in CSV 
					elif course[-1].lower() == 'yes' and not course[-3] and live_dict[course[1]]:
							warning = f'***WARNING: RESDEV ID not provided searching for ID {course[1]}'
							print(warning)
							error_log.append(warning)

							from_id = resdev_dict[course[-2]]
							to_id = live_dict[course[1]]
							print(f'copying to: {to_id} - {course[1]} from: {from_id} - {course[-2]}')
							content_migrator(from_id, to_id)   #intiates course copy
					else:
						error_log.append(f'ERROR: {course[1]} on READY list but not marked YES {course[-1]}')
						print(f'ERROR: {course[1]} on READY list but not marked YES {course[-1]}')
				else:
					if verify_xlist(course[1]):
						error_log.append(f'WARNING: {course[1]} is XLISTED')
						print(f'WARNING: {course[1]} is XLISTED')

					elif (verify_course_copy(course[1]) or verify_api_copy(live_dict[course[1]])):
						error_log.append(f'WARNING: {course[1]} content has been copied into this course before')
						print(f'WARNING: {course[1]} content has been copied into this course before')

			except KeyError as e :
				error_log.append(f'ERROR: {e} {course[1]} does not exist in Canvas')
				print(f'ERROR: {e} {course[1]} does not exist in Canvas')

		
def main():

	start_time = time.time()
	sysdate = datetime.today().strftime('%Y-%m-%d')

	print(f'RES COURSE COPY: {sysdate} \n\nsource file: {masterlist}')
	print(f'CANVAS INSTANCE: {INSTANCE}' %'\n' )

	file_url, file_name = get_provisioning_csv(account_id)	#generates a CANVAS provisioning report
	prov_report = get_file(file_url, file_name)				#downloads and moves file to desktop

	live_sections_dictionary(prov_report)					#provisioning report is turned into dictionary
	resdev_dictionary(SQL)									#runs SQL to get dictionary of resdevs in in Canvas									
	xlist_dictionary()										#runs SQL to get dictionary of xlisted courses in Banner
	copied_list()
	read_csv(masterlist)									#reads master list from Terry and if 'ready' initiate course copy

	delete_csv(prov_report, file_name)						#deletes downloaded provisioning report
	verify_migration()										#goes through list of migration urls to verify workflow state of running/completed
	error_handling(sysdate)									#creates a csv to log all processing errors and warnings

	print('\nTOTAL RUNTIME:', round(float(time.time()-start_time) / 60, 2), 'minutes')

if __name__ == "__main__":
	main()


